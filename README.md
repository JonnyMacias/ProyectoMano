# âœ‹ğŸ¤– Reconocimiento de SeÃ±ales en Tiempo Real usando LSTM

Este proyecto tiene como objetivo identificar en **tiempo real** la **seÃ±al mostrada con las manos** frente a una cÃ¡mara, utilizando un modelo de red neuronal LSTM previamente entrenado.

---

## ğŸ“Œ DescripciÃ³n general del flujo

1. ğŸ“¦ **RecolecciÃ³n del Dataset**  
   Se capturan imÃ¡genes y videos correspondientes a cada seÃ±a del lenguaje gestual. Estas se almacenan como base para el entrenamiento.

2. ğŸ” **ExtracciÃ³n de caracterÃ­sticas**  
   Para cada imagen o frame de video:
   - Se identifican los puntos clave de las manos.
   - Se calculan las **pendientes** y **Ã¡ngulos** entre estos puntos.
   - Los datos resultantes se agrupan segÃºn la seÃ±a correspondiente.

3. ğŸ§¾ **Almacenamiento en CSV**  
   Toda la informaciÃ³n procesada (pendientes y Ã¡ngulos) se guarda en archivos `.csv`, organizados por clase (una clase por seÃ±a).

4. ğŸ§  **Entrenamiento del modelo LSTM**  
   Se utiliza una red neuronal **LSTM (Long Short-Term Memory)** para aprender la secuencia de movimientos y formas de las manos correspondientes a cada seÃ±a.

5. ğŸŸ¢ **Reconocimiento en tiempo real**  
   Finalmente, con el modelo ya entrenado:
   - Se activa la cÃ¡mara.
   - Se detectan las manos en vivo.
   - Se calculan en tiempo real las pendientes y Ã¡ngulos.
   - Se hace una predicciÃ³n utilizando el modelo LSTM para identificar quÃ© seÃ±a se estÃ¡ mostrando.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Python**
- **OpenCV**
- **MediaPipe** (para la detecciÃ³n de manos y puntos clave)
- **NumPy / Pandas**
- **TensorFlow / Keras** (para construir y entrenar el modelo LSTM)
